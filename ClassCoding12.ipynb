{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVhvqjkd8f+IQudIq9kf/i"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t5J4JkeElnq0"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, weight_range=(-1, 1), bias_range=(-1, 1), resolution=0.1):\n",
        "        self.bias = 0.0\n",
        "        self.weights = None\n",
        "        self.weight_range = weight_range\n",
        "        self.bias_range = bias_range\n",
        "        self.resolution = resolution\n",
        "\n",
        "    def _sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def _cross_entropy_loss(self, y_true, y_pred):\n",
        "        y_pred = np.clip(y_pred, 1e-9, 1 - 1e-9)  # Avoid log(0)\n",
        "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "    def _feature_extraction(self, X):\n",
        "        # Convert string inputs to feature vectors (count 'a' occurrences)\n",
        "        return np.array([[x.count('a')] for x in X], dtype=np.float32)\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        X_train = self._feature_extraction(X_train)\n",
        "        n_samples, n_features = X_train.shape\n",
        "\n",
        "        best_loss = float('inf')\n",
        "        best_weights = None\n",
        "        best_bias = None\n",
        "\n",
        "        weight_values = np.arange(self.weight_range[0], self.weight_range[1], self.resolution)\n",
        "        bias_values = np.arange(self.bias_range[0], self.bias_range[1], self.resolution)\n",
        "\n",
        "        for w in weight_values:\n",
        "            for b in bias_values:\n",
        "                linear_model = np.dot(X_train, w) + b\n",
        "                y_pred = self._sigmoid(linear_model)\n",
        "                loss = self._cross_entropy_loss(y_train, y_pred)\n",
        "\n",
        "                if loss < best_loss:\n",
        "                    best_loss = loss\n",
        "                    best_weights = w\n",
        "                    best_bias = b\n",
        "\n",
        "        self.weights = np.array([best_weights])\n",
        "        self.bias = best_bias\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        X = self._feature_extraction(X)\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        return self._sigmoid(linear_model)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [1 if p >= 0.5 else 0 for p in self.predict_proba(X)]\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        y_pred = self.predict(X_test)\n",
        "        accuracy = np.mean(np.array(y_pred) == y_test)\n",
        "        return accuracy\n"
      ],
      "metadata": {
        "id": "PD_rtvjYmVX8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data\n",
        "X_train = [\n",
        "    \"aabaaabaaaaa\", \"bbaaaaab\", \"abbbbbbb\", \"babaabaaaaa\",\n",
        "    \"abbbbbbbbbbb\", \"bbbaabbb\", \"bbbbbbbbbbbbabb\", \"abaaaaaaaa\",\n",
        "    \"babbabbb\", \"abaababa\"\n",
        "]\n",
        "y_train = np.array([0, 0, 1, 0, 1, 1, 1, 0, 1, 0])\n",
        "\n",
        "X_test = [\"bbbbbbbbbbbabb\", \"baaaaaaaa\"]\n",
        "y_test = np.array([1, 0])\n"
      ],
      "metadata": {
        "id": "IU7H4QP7mZy4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = LogisticRegression(weight_range=(-2, 2), bias_range=(-2, 2), resolution=0.1)\n",
        "\n",
        "# Train model\n",
        "print(\"Training model...\")\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Test model\n",
        "print(\"Testing model...\")\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)\n",
        "accuracy = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mUX8AqSmdRd",
        "outputId": "25d2d9b0-b4af-49d5-c920-1541b68b5539"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model...\n",
            "Training complete.\n",
            "Testing model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display results\n",
        "print(\"Predicted probabilities:\", y_proba)\n",
        "print(\"Predicted labels:\", y_pred)\n",
        "print(\"Model accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBnl2pHVmjNx",
        "outputId": "588d39a5-4af3-46b7-f12b-f261d390cd76"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted probabilities: [0.5 0.5]\n",
            "Predicted labels: [1, 1]\n",
            "Model accuracy: 0.5\n"
          ]
        }
      ]
    }
  ]
}
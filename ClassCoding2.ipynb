{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyggppnRHO6ZpokskKsDT5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azoqi/Natural-Language-Processing/blob/main/ClassCoding2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem: we would like to know what traits define great authors by comparing the works of 3 historic and well-regarded authors: William Shakespeare, Jane Austen, and Charles Dickens. Specifically, we need to determine the total size of each authors vocabulary and the average length of a sentence in their works.\n",
        "\n",
        "\n",
        "\n",
        "Requirements: write a Python program using the Natural Language ToolkitLinks to an external site. to tokenize the works (or a subset) of each author retrieved from Project GutenbergLinks to an external site.. You should count the total number of unique words (types) that appear in the works of each author, as well as the average length of a sentence in the books. You do not have to use every book by the three authors in your investigation, but should use at least the 3 most popular complete novels. Exclude poetry as it will interfere with you investigation of sentence length.\n",
        "\n",
        "Your program should do a good job of cleaning and normalizing the tokens.\n"
      ],
      "metadata": {
        "id": "qoGEOtvYalLb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6uhzNytxXN5K"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import nltk\n",
        "import re\n",
        "import time\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "#tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "#sentences = tokenizer.tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_qRdj5tX6s1",
        "outputId": "37dd7b7a-a710-4dec-e561-48845fc4818a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_gutenberg_text(text):\n",
        "    start_match = re.search(r'\\*\\*\\*\\s*START OF (THIS|THE) PROJECT GUTENBERG EBOOK.*\\*\\*\\*', text)\n",
        "    end_match = re.search(r'\\*\\*\\*\\s*END OF (THIS|THE) PROJECT GUTENBERG EBOOK.*\\*\\*\\*', text)\n",
        "    if start_match and end_match:\n",
        "        text = text[start_match.end():end_match.start()]\n",
        "    return text"
      ],
      "metadata": {
        "id": "aXZu9oWiYKBD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "works = {\n",
        "    'Jane Austen': [\n",
        "        (\"Pride and Prejudice\", \"http://www.gutenberg.org/files/1342/1342-0.txt\"),\n",
        "        (\"Sense and Sensibility\", \"http://www.gutenberg.org/files/161/161-0.txt\"),\n",
        "        (\"Emma\", \"http://www.gutenberg.org/files/158/158-0.txt\")\n",
        "    ],\n",
        "    'Charles Dickens': [\n",
        "        (\"A Tale of Two Cities\", \"http://www.gutenberg.org/files/98/98-0.txt\"),\n",
        "        (\"Oliver Twist\", \"http://www.gutenberg.org/files/730/730-0.txt\"),\n",
        "        (\"Great Expectations\", \"http://www.gutenberg.org/files/1400/1400-0.txt\")\n",
        "    ],\n",
        "    'William Shakespeare': [\n",
        "        # Note: Shakespeareâ€™s works are plays. We use three popular ones.\n",
        "        (\"Hamlet\", \"https://www.gutenberg.org/files/2265/2265-0.txt\"),\n",
        "        (\"Macbeth\", \"https://www.gutenberg.org/files/2264/2264-0.txt\"),\n",
        "        (\"Romeo and Juliet\", \"https://www.gutenberg.org/files/1112/1112-0.txt\")\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "e9nuoG2yYN0b"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import nltk\n",
        "\n",
        "#nltk.download('punkt')\n",
        "\n",
        "results = {}\n",
        "\n",
        "for author, texts in works.items():\n",
        "    vocab = set()         # unique words for this author.\n",
        "    total_words = 0       # Total count of (cleaned) word tokens.\n",
        "    total_sentences = 0   # Total count of sentences.\n",
        "    print(f\"Processing texts for {author}...\")\n",
        "\n",
        "    for title, url in texts:\n",
        "        print(f\"  Downloading '{title}'...\")\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            response.encoding = 'utf-8'\n",
        "            text = response.text\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading '{title}': {e}\")\n",
        "            continue\n",
        "\n",
        "        text = clean_gutenberg_text(text)\n",
        "\n",
        "        # Tokenize the text into sentences.\n",
        "        sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "        for sentence in sentences:\n",
        "            # Tokenize the sentence into words.\n",
        "            words = nltk.word_tokenize(sentence)\n",
        "            cleaned_words = []\n",
        "            for token in words:\n",
        "                token = token.lower().strip(string.punctuation)\n",
        "                # Include the token only if it is alphabetic.\n",
        "                if token.isalpha():\n",
        "                    cleaned_words.append(token)\n",
        "                    vocab.add(token)\n",
        "            # Count words in this sentence (if any remain after cleaning).\n",
        "            if cleaned_words:\n",
        "                total_words += len(cleaned_words)\n",
        "                total_sentences += 1\n",
        "\n",
        "        # stop overloading Project Gutenberg's servers.\n",
        "        time.sleep(1)\n",
        "\n",
        "    # Calculate average sentence length.\n",
        "    avg_sentence_length = total_words / total_sentences if total_sentences > 0 else 0\n",
        "    results[author] = {\n",
        "        'vocab_size': len(vocab),\n",
        "        'avg_sentence_length': avg_sentence_length\n",
        "    }\n",
        "# Print out the results.\n",
        "print(\"\\n=== Analysis Results ===\")\n",
        "for author, data in results.items():\n",
        "    print(f\"\\nAuthor: {author}\")\n",
        "    print(f\"  Vocabulary Size: {data['vocab_size']}\")\n",
        "    print(f\"  Average Sentence Length: {data['avg_sentence_length']:.2f} words\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naH3VXSXYS0i",
        "outputId": "28a30070-119e-4ae9-a668-343bc165378b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing texts for Jane Austen...\n",
            "  Downloading 'Pride and Prejudice'...\n",
            "  Downloading 'Sense and Sensibility'...\n",
            "  Downloading 'Emma'...\n",
            "Processing texts for Charles Dickens...\n",
            "  Downloading 'A Tale of Two Cities'...\n",
            "  Downloading 'Oliver Twist'...\n",
            "  Downloading 'Great Expectations'...\n",
            "Processing texts for William Shakespeare...\n",
            "  Downloading 'Hamlet'...\n",
            "  Downloading 'Macbeth'...\n",
            "  Downloading 'Romeo and Juliet'...\n",
            "\n",
            "=== Analysis Results ===\n",
            "\n",
            "Author: Jane Austen\n",
            "  Vocabulary Size: 10455\n",
            "  Average Sentence Length: 27.49 words\n",
            "\n",
            "Author: Charles Dickens\n",
            "  Vocabulary Size: 16661\n",
            "  Average Sentence Length: 24.84 words\n",
            "\n",
            "Author: William Shakespeare\n",
            "  Vocabulary Size: 3924\n",
            "  Average Sentence Length: 15.53 words\n"
          ]
        }
      ]
    }
  ]
}